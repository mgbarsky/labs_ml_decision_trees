{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting course evaluations with Decision Trees\n",
    "\n",
    "\n",
    "## 1. CART Algorithm Implementation\n",
    "\n",
    "### 1.1. Tree data structure and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "        self.col = col # attribute on which to split\n",
    "        self.value = value # value on which to split\n",
    "        self.results = results # If the node has no children - we store here class labels with their counts\n",
    "        self.tb = tb  # True branch\n",
    "        self.fb = fb  # False branch\n",
    "        \n",
    "def split(rows, column, value):\n",
    "    # define split function according to the value type\n",
    "    split_function = None\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        split_function = lambda row: row[column] >= value\n",
    "    else:\n",
    "        split_function = lambda row: row[column] == value\n",
    "\n",
    "    # Divide the rows into two sets and return them\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "    return (set1, set2)\n",
    "\n",
    "def count_labels(rows):\n",
    "    label_count = {}\n",
    "    for row in rows:\n",
    "        # The class label is in the last column\n",
    "        label = row[- 1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Node purity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def gini_impurity(rows):\n",
    "    total = len(rows)\n",
    "    counts = count_labels(rows)\n",
    "    gini = 0\n",
    "    for key, val in counts.items():\n",
    "        p = val / total\n",
    "        gini += p*p\n",
    "        \n",
    "    return (1 - gini)\n",
    "\n",
    "def entropy(rows):\n",
    "    total = len(rows)\n",
    "    counts = count_labels(rows)\n",
    "    ent = 0.0\n",
    "    for key,val in counts.items():\n",
    "        p = val / total\n",
    "        ent = ent - p * log(p, 2)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def variance(rows):\n",
    "    if len(rows) == 0: return 0\n",
    "    num_label = [float(row[- 1]) for row in rows]\n",
    "    mean = sum(num_label) / len(num_label)\n",
    "    variance = sum([(d - mean) ** 2 for d in num_label]) / len(num_label)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Tree induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildtree(rows, score_func=entropy, min_improvement=0, min_samples=0, max_depth=None, depth=0):\n",
    "    if len(rows) == 0:\n",
    "        return DecisionNode()\n",
    "    # Compute overall score for the entire rows dataset\n",
    "    current_score = score_func(rows)\n",
    "\n",
    "    # Set up accumulator variables to track the best split criteria\n",
    "    best_score = current_score\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "    \n",
    "    # Total number of features - except the last column where we store the class (target)\n",
    "    column_count = len(rows[0]) - 1 \n",
    "    for col in range(0, column_count):\n",
    "        # Generate the list of unique values in\n",
    "        # this column to split on them\n",
    "        column_values = set()\n",
    "        for row in rows:\n",
    "            column_values.add(row[col])\n",
    "            \n",
    "        # Now try splitting the rows \n",
    "        # on each unique value in this column\n",
    "        for value in column_values:\n",
    "            (set1, set2) = split(rows, col, value)\n",
    "\n",
    "            # Evaluate the quality of the split\n",
    "            # p is the proportion of subset set1 \n",
    "            p = float(len(set1)) / len(rows)\n",
    "            split_score = p * score_func(set1) + (1-p) * score_func(set2)\n",
    "            \n",
    "            if split_score < best_score and \\\n",
    "                (len(set1) > min_samples and len(set2) > min_samples) and \\\n",
    "                (current_score - split_score) > min_improvement:\n",
    "                best_score = split_score\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1, set2)\n",
    "\n",
    "    # Create the sub branches\n",
    "    if (current_score - best_score) > min_improvement and \\\n",
    "        (max_depth is None or depth < max_depth) :\n",
    "        # print(\"Splitting on\",best_criteria, \" 2 sets:\", len(best_sets[0]),len(best_sets[1]))\n",
    "        true_branch = buildtree(best_sets[0], score_func, min_improvement, min_samples, max_depth, depth+1)\n",
    "        false_branch = buildtree(best_sets[1], score_func, min_improvement, min_samples, max_depth, depth+1)\n",
    "        return DecisionNode(col=best_criteria[0], value=best_criteria[1],\n",
    "                            tb=true_branch, fb=false_branch)\n",
    "    else: # Done splitting - summarize class labels in leaf nodes\n",
    "        return DecisionNode(results=count_labels(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Tree printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(leaf_labels):\n",
    "    total = 0\n",
    "    result = {}\n",
    "    for label, count in leaf_labels.items():\n",
    "        total += count\n",
    "        result[label] = count\n",
    "\n",
    "    for label, val in result.items():\n",
    "        result[label] = str(int(result[label]/total * 100))+\"%\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree, current_branch, attributes=None,  indent='', leaf_funct=prediction):\n",
    "    # Is this a leaf node?\n",
    "    if tree.results != None:\n",
    "        print(indent + current_branch + str(leaf_funct(tree.results)))\n",
    "    else:\n",
    "        # Print the split question\n",
    "        split_col = str(tree.col)\n",
    "        if attributes is not None:\n",
    "            split_col = attributes[tree.col]\n",
    "        split_val = str(tree.value)\n",
    "        if type(tree.value) == int or type(tree.value) == float:\n",
    "            split_val = \">=\" + str(tree.value)\n",
    "        print(indent + current_branch + split_col + ': ' + split_val + '? ')\n",
    "\n",
    "        # Print the branches\n",
    "        indent = indent + '  '\n",
    "        print_tree(tree.tb, 'T->', attributes, indent)\n",
    "        print_tree(tree.fb, 'F->', attributes, indent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return prediction(tree.results)\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        branch = None\n",
    "        if isinstance(v, int) or isinstance(v, float):\n",
    "            if v >= tree.value:\n",
    "                branch = tree.tb\n",
    "            else:\n",
    "                branch = tree.fb\n",
    "        else:\n",
    "            if v == tree.value:\n",
    "                branch = tree.tb\n",
    "            else:\n",
    "                branch = tree.fb\n",
    "        return classify(observation, branch)\n",
    "\n",
    "\n",
    "# Classify an observation with missing data\n",
    "def mdclassify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return prediction(tree.results)\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        if v == None:\n",
    "            tr, fr = mdclassify(observation, tree.tb), mdclassify(observation, tree.fb)\n",
    "            tcount = sum(tr.values())\n",
    "            fcount = sum(fr.values())\n",
    "            tw = float(tcount) / (tcount + fcount)\n",
    "            fw = float(fcount) / (tcount + fcount)\n",
    "            result = {}\n",
    "            for k, v in tr.items(): result[k] = v * tw\n",
    "            for k, v in fr.items(): result[k] = v * fw\n",
    "            return result\n",
    "        else:\n",
    "            if isinstance(v, int) or isinstance(v, float):\n",
    "                if v >= tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            else:\n",
    "                if v == tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            return mdclassify(observation, branch)\n",
    "\n",
    "def max_depth(tree):\n",
    "    if tree.results != None:\n",
    "        return 0\n",
    "    else:\n",
    "        # Compute the depth of each subtree\n",
    "        tDepth = max_depth(tree.tb)\n",
    "        fDepth = max_depth(tree.fb)\n",
    "\n",
    "        # Use the larger one\n",
    "        if (tDepth > fDepth):\n",
    "            return tDepth + 1\n",
    "        else:\n",
    "            return fDepth + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset to numeric\n",
    "\n",
    "The dataset for this lab contains about 450 anonymized student evaluations collected at the University of Texas at Austin, and used in the following publication: __\"Beauty in the Classroom: Instructors' Pulchritude and Putative Pedagogical Productivity\"__. You can learn how the data was collected and the meaning of various data attributes following this [link](https://chance.amstat.org/2013/04/looking-good/).\n",
    "\n",
    "We use a subset of attributes: 'rank', 'ethnicity', 'gender', 'language', 'age', 'class_size', 'class_level',  'avg_beauty_score',  and 'professor_evaluation_score' and try to predict course evaluation score. \n",
    "\n",
    "This smaller dataset can be downloaded from [here](https://drive.google.com/file/d/18wV59AYCVCqL1BIDBYLpL73emp7h8d0T/view?usp=sharing). Download the dataset into your data directory, and update the path to your file in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"C:/Users/10705/Desktop/Notebooks/labs_ml_optimizations/StudentEvaluations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the dataset into a data frame _df_. First, we will make all attributes numeric, and then we will convert all attributes to categorical labels. The _df_ points to the original dataset. We are going to create two copies: _df_num_ and _df_cat_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rank     ethnicity  gender language  age  cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english   36            43     upper   \n",
      "1  tenure track      minority  female  english   36           125     upper   \n",
      "2  tenure track      minority  female  english   36           125     upper   \n",
      "3  tenure track      minority  female  english   36           123     upper   \n",
      "4       tenured  not minority    male  english   59            20     upper   \n",
      "5       tenured  not minority    male  english   59            40     upper   \n",
      "6       tenured  not minority    male  english   59            44     upper   \n",
      "\n",
      "   bty_avg  prof_eval  course_eval  \n",
      "0      5.0        4.7          4.3  \n",
      "1      5.0        4.1          3.7  \n",
      "2      5.0        3.9          3.6  \n",
      "3      5.0        4.8          4.4  \n",
      "4      3.0        4.6          4.5  \n",
      "5      3.0        4.3          4.0  \n",
      "6      3.0        2.8          2.1  \n"
     ]
    }
   ],
   "source": [
    "print(df[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that not all attributes are numeric. Let's make them all numeric by using the pandas _replace_ method (see [this post](https://www.geeksforgeeks.org/how-to-convert-categorical-variable-to-numeric-in-pandas/)), which replaces the original values with the predefined set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a copy of the original data frame\n",
    "df_num = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace 'rank', 'ethnicity', 'gender', 'language', and 'cls_level' columns.\n",
    "Let's find out what are the values in each column - to know what to replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tenure track', 'tenured', 'teaching'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank\n",
    "df_num['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minority', 'not minority'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ethnicity\n",
    "df_num['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender\n",
    "df_num['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['english', 'non-english'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language\n",
    "df_num['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['upper', 'lower'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class level\n",
    "df_num['cls_level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a numeric code to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num['rank'].replace(['tenure track', 'tenured', 'teaching'], [1, 2, 3], inplace=True)\n",
    "df_num['ethnicity'].replace(['minority', 'not minority'], [1, 0], inplace=True)\n",
    "df_num['gender'].replace(['female', 'male'], [1, 2], inplace=True)\n",
    "df_num['language'].replace(['english', 'non-english'], [1, 0], inplace=True)\n",
    "df_num['cls_level'].replace(['upper', 'lower'], [2,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the class label an integer by rounding course evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num['course_eval'] = df_num['course_eval'].round(0).astype(int)\n",
    "\n",
    "df_num['course_eval'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check what it looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>language</th>\n",
       "      <th>age</th>\n",
       "      <th>cls_students</th>\n",
       "      <th>cls_level</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>prof_eval</th>\n",
       "      <th>course_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  ethnicity  gender  language  age  cls_students  cls_level  bty_avg  \\\n",
       "0     1          1       1         1   36            43          2      5.0   \n",
       "1     1          1       1         1   36           125          2      5.0   \n",
       "2     1          1       1         1   36           125          2      5.0   \n",
       "3     1          1       1         1   36           123          2      5.0   \n",
       "4     2          0       2         1   59            20          2      3.0   \n",
       "5     2          0       2         1   59            40          2      3.0   \n",
       "6     2          0       2         1   59            44          2      3.0   \n",
       "\n",
       "   prof_eval  course_eval  \n",
       "0        4.7            4  \n",
       "1        4.1            4  \n",
       "2        3.9            4  \n",
       "3        4.8            4  \n",
       "4        4.6            4  \n",
       "5        4.3            4  \n",
       "6        2.8            2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore if there is any correlation between course score and any other attributes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  rank  ethnicity    gender  language       age  cls_students  \\\n",
      "rank          1.000000  -0.159577  0.107016  0.223881  0.413781     -0.055987   \n",
      "ethnicity    -0.159577   1.000000 -0.114642 -0.292186 -0.103120     -0.096993   \n",
      "gender        0.107016  -0.114642  1.000000  0.003805  0.285088      0.125560   \n",
      "language      0.223881  -0.292186  0.003805  1.000000  0.002055      0.086507   \n",
      "age           0.413781  -0.103120  0.285088  0.002055  1.000000     -0.012626   \n",
      "cls_students -0.055987  -0.096993  0.125560  0.086507 -0.012626      1.000000   \n",
      "cls_level    -0.074766  -0.136129 -0.056579 -0.143448  0.091463     -0.203698   \n",
      "bty_avg      -0.104417   0.041319 -0.134767 -0.014612 -0.304603      0.099003   \n",
      "prof_eval     0.078811  -0.075824  0.128607  0.108284 -0.107032      0.025970   \n",
      "course_eval   0.170265  -0.028295  0.139125  0.133564 -0.032688     -0.004621   \n",
      "\n",
      "              cls_level   bty_avg  prof_eval  course_eval  \n",
      "rank          -0.074766 -0.104417   0.078811     0.170265  \n",
      "ethnicity     -0.136129  0.041319  -0.075824    -0.028295  \n",
      "gender        -0.056579 -0.134767   0.128607     0.139125  \n",
      "language      -0.143448 -0.014612   0.108284     0.133564  \n",
      "age            0.091463 -0.304603  -0.107032    -0.032688  \n",
      "cls_students  -0.203698  0.099003   0.025970    -0.004621  \n",
      "cls_level      1.000000 -0.034028  -0.083705    -0.141472  \n",
      "bty_avg       -0.034028  1.000000   0.187142     0.176258  \n",
      "prof_eval     -0.083705  0.187142   1.000000     0.794968  \n",
      "course_eval   -0.141472  0.176258   0.794968     1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "corr = df_num.corr()\n",
    "print(corr)\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree: numeric dataset\n",
    "### 3.1. Using our custom CART algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_rows = df_num.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_num.columns.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be a regression tree, as we are trying to predict a numeric score. We have to use __variance__ as a measure of node purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(data_rows, score_func=variance, min_improvement=0, min_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_eval: >=3.8? \n",
      "  T->prof_eval: >=4.8? \n",
      "    T->cls_students: >=39.0? \n",
      "      T->{4.0: '50%', 5.0: '50%'}\n",
      "      F->cls_level: >=2.0? \n",
      "        T->{5.0: '78%', 4.0: '21%'}\n",
      "        F->prof_eval: >=4.9? \n",
      "          T->{5.0: '100%'}\n",
      "          F->{5.0: '90%', 4.0: '9%'}\n",
      "    F->prof_eval: >=4.6? \n",
      "      T->cls_students: >=27.0? \n",
      "        T->prof_eval: >=4.7? \n",
      "          T->{4.0: '84%', 5.0: '15%'}\n",
      "          F->{4.0: '100%'}\n",
      "        F->cls_students: >=19.0? \n",
      "          T->{4.0: '15%', 5.0: '84%'}\n",
      "          F->{4.0: '72%', 5.0: '27%'}\n",
      "      F->prof_eval: >=3.9? \n",
      "        T->cls_students: >=21.0? \n",
      "          T->bty_avg: >=4.833? \n",
      "            T->rank: >=2.0? \n",
      "              T->bty_avg: >=5.167? \n",
      "                T->{4.0: '100%'}\n",
      "                F->{4.0: '91%', 3.0: '8%'}\n",
      "              F->{4.0: '80%', 3.0: '20%'}\n",
      "            F->{4.0: '100%'}\n",
      "          F->prof_eval: >=4.3? \n",
      "            T->bty_avg: >=4.333? \n",
      "              T->{4.0: '92%', 5.0: '7%'}\n",
      "              F->{4.0: '83%', 5.0: '16%'}\n",
      "            F->{4.0: '100%'}\n",
      "        F->{4.0: '84%', 3.0: '15%'}\n",
      "  F->prof_eval: >=3.5? \n",
      "    T->age: >=50.0? \n",
      "      T->bty_avg: >=3.333? \n",
      "        T->{3.0: '21%', 4.0: '78%'}\n",
      "        F->{4.0: '57%', 3.0: '42%'}\n",
      "      F->rank: >=2.0? \n",
      "        T->{4.0: '45%', 3.0: '54%'}\n",
      "        F->{3.0: '75%', 4.0: '25%'}\n",
      "    F->prof_eval: >=3.0? \n",
      "      T->cls_students: >=23.0? \n",
      "        T->{3.0: '100%'}\n",
      "        F->{3.0: '76%', 4.0: '23%'}\n",
      "      F->{2.0: '36%', 3.0: '63%'}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, '', columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Using sklearn library\n",
    "The decision tree algorithm in sklearn library is not implemented very well. It requires all the attributes to be numeric - while decision trees work best with the categorical attributes. Nevertheless, we will try to run it and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class label has to be binary. So we are going to replace the 'course_eval' column with 3 bins, corresponding to the score:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide dataset into features and class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval'],\n",
      "      dtype='object')\n",
      "Index(['course_eval'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = df_num.loc[:, df_num.columns != 'course_eval']\n",
    "print(X.columns)\n",
    "\n",
    "Y = df_num.loc[:, df_num.columns == 'course_eval']\n",
    "print(Y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset intro training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different parameters can be specified to build the model:\n",
    "\n",
    "`model = tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', \n",
    "        max_depth=None, \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1, \n",
    "        max_features=None, \n",
    "        random_state=None, \n",
    "        min_density=None, \n",
    "        compute_importances=None, \n",
    "        max_leaf_nodes=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 4)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- prof_eval <= 3.75\n",
      "|   |--- prof_eval <= 3.45\n",
      "|   |   |--- prof_eval <= 2.60\n",
      "|   |   |   |--- class: 2\n",
      "|   |   |--- prof_eval >  2.60\n",
      "|   |   |   |--- bty_avg <= 5.83\n",
      "|   |   |   |   |--- class: 3\n",
      "|   |   |   |--- bty_avg >  5.83\n",
      "|   |   |   |   |--- class: 3\n",
      "|   |--- prof_eval >  3.45\n",
      "|   |   |--- age <= 48.00\n",
      "|   |   |   |--- cls_students <= 93.50\n",
      "|   |   |   |   |--- class: 3\n",
      "|   |   |   |--- cls_students >  93.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- age >  48.00\n",
      "|   |   |   |--- cls_students <= 110.00\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- cls_students >  110.00\n",
      "|   |   |   |   |--- class: 3\n",
      "|--- prof_eval >  3.75\n",
      "|   |--- prof_eval <= 4.55\n",
      "|   |   |--- cls_students <= 20.50\n",
      "|   |   |   |--- prof_eval <= 4.25\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- prof_eval >  4.25\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- cls_students >  20.50\n",
      "|   |   |   |--- rank <= 1.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- rank >  1.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |--- prof_eval >  4.55\n",
      "|   |   |--- cls_students <= 36.50\n",
      "|   |   |   |--- age <= 60.50\n",
      "|   |   |   |   |--- class: 5\n",
      "|   |   |   |--- age >  60.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- cls_students >  36.50\n",
      "|   |   |   |--- prof_eval <= 4.75\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- prof_eval >  4.75\n",
      "|   |   |   |   |--- class: 4\n",
      "\n",
      "[3 4 4]\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 4)\n",
    "model.fit(X_train,Y_train)\n",
    "columns_list = df_num.columns.to_numpy().tolist()\n",
    "from sklearn.tree import export_text\n",
    "r = export_text(model, feature_names=columns_list[:-1])\n",
    "print(r)\n",
    "predictdf = pd.read_csv(\"C:/Users/10705/Desktop/Notebooks/labs_ml_optimizations/predict.csv\")\n",
    "testpredict = model.predict([[2,0,2,1,70,12,2,5,3],[1,0,1,1,35,50,2,7,5],[1,0,1,1,50,25,2,5,4]])\n",
    "print(testpredict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(model,out_file='tree.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Categorical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to replace all the numeric columns in _df_ by categorical labels, using [Pandas _cut_ method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html).\n",
    "\n",
    "First we create a copy of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n",
      "           rank     ethnicity  gender language  age  cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english   36            43     upper   \n",
      "1  tenure track      minority  female  english   36           125     upper   \n",
      "2  tenure track      minority  female  english   36           125     upper   \n",
      "3  tenure track      minority  female  english   36           123     upper   \n",
      "4       tenured  not minority    male  english   59            20     upper   \n",
      "\n",
      "   bty_avg  prof_eval  course_eval  \n",
      "0      5.0        4.7          4.3  \n",
      "1      5.0        4.1          3.7  \n",
      "2      5.0        3.9          3.6  \n",
      "3      5.0        4.8          4.4  \n",
      "4      3.0        4.6          4.5  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)\n",
    "print(df_cat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to bin columns 'age', 'cls_students', 'bty_avg', 'prof_eval', and 'course_eval'. Everything else is already categorical.\n",
    "\n",
    "First thing is to determine the domain for each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 29 to 73\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "age_column = df_cat[\"age\"]\n",
    "print(\"From:\", age_column.min(), \"to\", age_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1.667 to 8.167\n"
     ]
    }
   ],
   "source": [
    "# Beauty score\n",
    "bty_ave_column = df_cat[\"bty_avg\"]\n",
    "print(\"From:\", bty_ave_column.min(), \"to\", bty_ave_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 8 to 581\n"
     ]
    }
   ],
   "source": [
    "# Class size\n",
    "num_students_column = df_cat[\"cls_students\"]\n",
    "print(\"From:\", num_students_column.min(), \"to\", num_students_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2.3 to 5.0\n"
     ]
    }
   ],
   "source": [
    "# Professor score\n",
    "prof_eval_column = df_cat[\"prof_eval\"]\n",
    "print(\"From:\", prof_eval_column.min(), \"to\", prof_eval_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2.1 to 5.0\n"
     ]
    }
   ],
   "source": [
    "# Course score (class label)\n",
    "course_eval_column = df_cat[\"course_eval\"]\n",
    "print(\"From:\", course_eval_column.min(), \"to\", course_eval_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Age to bins\n",
    "bins = [20, 35, 50, 65, np.inf]\n",
    "names = [ '20-35', '35-50',  '50-65', '65+']\n",
    "\n",
    "df_cat['age'] = pd.cut(df_cat['age'], bins, labels=names)\n",
    "\n",
    "# Class size to bins\n",
    "bins = [0, 15, 30, 50, 100, np.inf]\n",
    "names = [ '<15', '15-30',  '30-50', '50-100', '100+']\n",
    "\n",
    "df_cat['cls_students'] = pd.cut(df_cat['cls_students'], bins, labels=names)\n",
    "\n",
    "# Beauty average to bins\n",
    "bins = [0, 3, 6, 9, np.inf]\n",
    "names = [ '<3', '3-6',  '6-9', '9+']\n",
    "\n",
    "df_cat['bty_avg'] = pd.cut(df_cat['bty_avg'], bins, labels=names)\n",
    "\n",
    "# Professor score to bins\n",
    "bins = [0, 2, 3, 4, 4.5, np.inf]\n",
    "names = [ '<2', '2-3',  '3-4', '4-4.5', '4.5+']\n",
    "\n",
    "df_cat['prof_eval'] = pd.cut(df_cat['prof_eval'], bins, labels=names)\n",
    "\n",
    "# Course score to class label\n",
    "bins = [0, 2, 3, 4, 4.5, np.inf]\n",
    "names = [ 'bad', 'fair',  'average', 'good', 'excellent']\n",
    "\n",
    "df_cat['course_eval'] = pd.cut(df_cat['course_eval'], bins, labels=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n",
      "           rank     ethnicity  gender language    age cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english  35-50        30-50     upper   \n",
      "1  tenure track      minority  female  english  35-50         100+     upper   \n",
      "2  tenure track      minority  female  english  35-50         100+     upper   \n",
      "3  tenure track      minority  female  english  35-50         100+     upper   \n",
      "4       tenured  not minority    male  english  50-65        15-30     upper   \n",
      "\n",
      "  bty_avg prof_eval course_eval  \n",
      "0     3-6      4.5+        good  \n",
      "1     3-6     4-4.5     average  \n",
      "2     3-6       3-4     average  \n",
      "3     3-6      4.5+        good  \n",
      "4      <3      4.5+        good  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)\n",
    "print(df_cat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Tree: categorical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_rows = df_cat.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_cat.columns.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a decision tree (classification), we use entropy as a measure of leaf purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(data_rows, score_func=entropy, min_improvement=0, min_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_eval: 4.5+? \n",
      "  T->cls_students: 15-30? \n",
      "    T->{'good': '19%', 'excellent': '80%'}\n",
      "    F->gender: male? \n",
      "      T->{'good': '51%', 'excellent': '46%', 'average': '2%'}\n",
      "      F->{'good': '61%', 'average': '6%', 'excellent': '32%'}\n",
      "  F->prof_eval: 4-4.5? \n",
      "    T->cls_students: 30-50? \n",
      "      T->{'average': '56%', 'good': '43%'}\n",
      "      F->cls_level: upper? \n",
      "        T->age: 50-65? \n",
      "          T->{'average': '25%', 'good': '72%', 'excellent': '2%'}\n",
      "          F->{'average': '40%', 'good': '52%', 'excellent': '7%'}\n",
      "        F->{'average': '41%', 'good': '58%'}\n",
      "    F->ethnicity: not minority? \n",
      "      T->bty_avg: <3? \n",
      "        T->{'fair': '25%', 'average': '74%'}\n",
      "        F->gender: female? \n",
      "          T->{'average': '81%', 'fair': '18%'}\n",
      "          F->{'average': '93%', 'fair': '6%'}\n",
      "      F->{'average': '84%', 'fair': '12%', 'good': '3%'}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, '', columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best we could do for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [TASK 1] Using learned tree for classification\n",
    "\n",
    "Recall at least 3 different courses you have taken, and record the values of the attributes, and the course score that you have given to the course. Run the predict function to see if the decision tree correctly predicts your score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am thinking about three lessons with the following attributes in numeric values:[2,0,2,1,70,12,2,5,3], [1,0,1,1,35,50,2,7,5],[1,0,1,1,50,25,2,5,4]. It means that the first one is taught by a old male professor that is of average beauty, small class size, and moderate professor evaluation. The second one is a younger female assistant prof in a large class, with above average beauty and good prof evaluation. The third one is a older assistant prof that is having a moderate size class and is having average beauty and fine evaluation. The result in my mind is 3,5,4, yet the predict is 3,4,4 which underestimated the score. This is probably because there is no score 5 available as the scores are at most 4 as the evaluation is of type int, or the training set is flawed, just some possible reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [TASK 2] Important factors\n",
    "What are the most important attributes in separating good course evaluations from the bad ones? Support your answer by analyzing the tree levels and the leaf outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to use the graphviz to see the tree for sklearn method, and by limiting the tree height to be 4, the result shows that out of 14 total non-leaf nodes, 6 of them are about prof evaluation, which is consistent with the result from evaluation, and as the node fully determines the first two layer, as well as 2 out of 7 non-leaf nodes in the fourth layer, I think the prof evaluation is important. Out of 15 total leaves, 5 are directly related to prof evaluation, and generally, by looking closely at layer 2, if prof eval > 3.75, the course is much more likely to have a score higher than 3. Other than that, age and class size seems to also play a role in splitting the evaluation but it is less important than prof evaluation. It seems that if the prof is too young and the prof eval is less than 3.75, the course is more likely to have a lower score, while if the prof eval is greater than 3.75, prof younder than 60 is more likely to get a score of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. [TASK 3] Rules\n",
    "Extract from the tree at least 3 rules that you find most reliable. Did any of these rules surprise you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am mostly looking at categorical data with min size of 30.   \n",
    "Rule1: if prof evaluation is higher than 4.55, the class size is between 15-30, then the course evaluation score is guaranteed to be larger or equal to 4.    \n",
    "Rule2: if prof evaluation is lower than 4, and class size is not between 30-50, and the prof is not minority, the course score is between 2 and 4.   \n",
    "Rule3:if prof evaluation is less than 4, and the professor is not minority, and the professor has beauty score greater or equal to 3, the course evaluation is highly likely to be average, and is guaranteed to be either average or fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. [BONUS] Web visualization\n",
    "The visualizations of the tree can be made much more expressive with the _d3.js_ visualization library. Sample  _public_html_ folder containing all the required html, css, and javascript files, including the library itself, is provided. \n",
    "\n",
    "In order to create this visualization, all you need is a json file which represents the nodes of the final decision tree. Learn the required JSON format, and implement this conversion in a separate file __dtree_to_json.py__. Submit your file with the lab. \n",
    "\n",
    "Copy the resulting json file into the data directory in the _public_html_ folder, and update the name of the json file in the JavaScript code on line 39 in _index.html_. \n",
    "\n",
    "Note that Chrome would not allow you to run the visualization locally - so if you want to present it to the world you should use a web server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chance.amstat.org/2013/04/looking-good/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chance.amstat.org/2013/04/looking-good/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
